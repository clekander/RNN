{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52826d40",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Gabs DiLiegro, London Kasper, Carys LeKander\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset?select=spam.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565fb1a1",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Our dataset is a collection of text messages that are identified as normal or spam texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51360b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      5572 non-null   object\n",
      " 1   v2      5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('spam.csv',encoding='latin-1')\n",
    "df = df.drop(['Unnamed: 2','Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83598b",
   "metadata": {},
   "source": [
    "The first column of our dataset identifies if it is a spam text. We used label encoding below to change the column to be 0 for a normal text and 1 for a spam text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f7e0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['v1'])\n",
    "df['v1'] = le.transform(df['v1'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af1766",
   "metadata": {},
   "source": [
    "Looking at the totals for each category, we can see that there are many more normal text messages than spam messages in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5991375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals = df['v1'].value_counts()\n",
    "totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fbb2d2",
   "metadata": {},
   "source": [
    "The longest text message in our dataset is 171 which we will use for our max length during tokenization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e71155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 0\n",
    "for i in df.v2:\n",
    "    if len(i.split()) > max_words:\n",
    "        max_words = len(i.split())\n",
    "max_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6187c0",
   "metadata": {},
   "source": [
    "For our tokenization, we converted each word to an integer using the Keras Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06fa4d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 12:41:38.872962: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8920 unique tokens. Distilled to 8920 top words.\n",
      "Shape of data tensor: (5572, 171)\n",
      "CPU times: user 8.32 s, sys: 1.86 s, total: 10.2 s\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "NUM_TOP_WORDS = None # use entire vocabulary!\n",
    "MAX_ART_LEN = max_words # maximum and minimum number of words\n",
    "\n",
    "#tokenize the text\n",
    "tokenizer = Tokenizer(num_words=NUM_TOP_WORDS)\n",
    "tokenizer.fit_on_texts(df.v2)\n",
    "# save as sequences with integers replacing words\n",
    "sequences = tokenizer.texts_to_sequences(df.v2)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "NUM_TOP_WORDS = len(word_index) if NUM_TOP_WORDS==None else NUM_TOP_WORDS\n",
    "top_words = min((len(word_index),NUM_TOP_WORDS))\n",
    "print('Found %s unique tokens. Distilled to %d top words.' % (len(word_index),top_words))\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "y = df.v1.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61fa95",
   "metadata": {},
   "source": [
    "For our business case, we want to notify users when they recieve a text that may be spam. If we misclassify something as spam, the user may be slightly annoyed. However, if we do not clasify something as spam when it is, it could lead to the user trusting a fraudulent text. Therefore we want to minimize the number of false negative (number of spam texts classified as normal texts), so we will use recall to measure our algorithm's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58da1a",
   "metadata": {},
   "source": [
    "We chose to use a Stratified 10-fold cross validation for dividing our data into training and testing. We chose this method because our dataset is smaller (5572) and there are not many examples of spam texts (747). We want to make sure that we represent the entire dataset in equal proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b083d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "y_train = y_train.values.astype(np.int32)\n",
    "y_test = y_test.values.astype(np.int32)\n",
    "kfold = StratifiedKFold(n_splits=10).split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542cad62",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ca36fa",
   "metadata": {},
   "source": [
    "For our modeling, we decided to investigate LSTM and GRU recurrent network architectures. To start, we used GloVe pre-trained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7bb7789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Embedding Shape: (8921, 100) \n",
      " Total words found: 6518 \n",
      " Percentage: 73.06355789709674\n",
      "CPU times: user 17.8 s, sys: 1.16 s, total: 18.9 s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EMBED_SIZE = 100\n",
    "# the embed size should match the file you load glove from\n",
    "embeddings_index = {}\n",
    "f = open('large_data/glove.6b/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "# save key/array pairs of the embeddings\n",
    "#  the key of the dictionary is the word, the array is the embedding\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# now fill in the matrix, using the ordering from the\n",
    "#  keras word tokenizer from before\n",
    "found_words = 0\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be ALL-ZEROS\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        found_words = found_words+1\n",
    "\n",
    "print(\"Embedding Shape:\",embedding_matrix.shape, \"\\n\",\n",
    "      \"Total words found:\",found_words, \"\\n\",\n",
    "      \"Percentage:\",100*found_words/embedding_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbfd30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, GRU\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ecd657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this embedding now\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBED_SIZE,\n",
    "                            weights=[embedding_matrix],# here is the embedding getting saved\n",
    "                            input_length=MAX_ART_LEN,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2be94",
   "metadata": {},
   "source": [
    "Our first two models are LSTM models. We adjusted the hyper-parameters for the recurrent dropout for our second model. In our first model, the reccurent dropout is 0.2, while in the second model it is 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bd4b143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 12:42:23.470605: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 171, 100)          892100    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 972,601\n",
      "Trainable params: 80,501\n",
      "Non-trainable params: 892,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm1 = Sequential()\n",
    "lstm1.add(embedding_layer)\n",
    "lstm1.add(LSTM(100,dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(lstm1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db12c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 171, 100)          892100    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 972,601\n",
      "Trainable params: 80,501\n",
      "Non-trainable params: 892,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm2 = Sequential()\n",
    "lstm2.add(embedding_layer)\n",
    "lstm2.add(LSTM(100,dropout=0.2, recurrent_dropout=0.3))\n",
    "lstm2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(lstm2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe677ed",
   "metadata": {},
   "source": [
    "Our last two models are GRU models. We adjusted the hyper-parameters for the recurrent dropout for our fourth model. In our thrid model, the reccurent dropout is 0.2, while in the fourth model it is 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b9871c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 171, 100)          892100    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 100)               60600     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 952,801\n",
      "Trainable params: 60,701\n",
      "Non-trainable params: 892,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gru1 = Sequential()\n",
    "gru1.add(embedding_layer)\n",
    "gru1.add(GRU(100,dropout=0.2, recurrent_dropout=0.2))\n",
    "gru1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(gru1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76950efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 171, 100)          892100    \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 100)               60600     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 952,801\n",
      "Trainable params: 60,701\n",
      "Non-trainable params: 892,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gru2 = Sequential()\n",
    "gru2.add(embedding_layer)\n",
    "gru2.add(GRU(100,dropout=0.2, recurrent_dropout=0.3))\n",
    "gru2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(gru2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8e05aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "def roc(model, test, train, mean_tpr):\n",
    "    probas = model.predict(X_train[test], verbose=0)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train[test], probas, pos_label=1)\n",
    "    mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    return mean_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd3e7c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1 ...\n",
      "Score for LSTM1: loss of 0.07279717922210693; accuracy of 97.98206090927124%; recall of 86.8852436542511%\n",
      "Score for LSTM2: loss of 0.09602268040180206; accuracy of 97.53363132476807%; recall_1 of 86.8852436542511%\n",
      "Score for GRU1: loss of 0.08886227756738663; accuracy of 97.30941653251648%; recall_2 of 85.24590134620667%\n",
      "Score for GRU2: loss of 0.08136230707168579; accuracy of 97.53363132476807%; recall_3 of 85.24590134620667%\n",
      "Training for fold 2 ...\n",
      "Score for LSTM1: loss of 0.0837450847029686; accuracy of 97.53363132476807%; recall_4 of 88.52459192276001%\n",
      "Score for LSTM2: loss of 0.07517705857753754; accuracy of 98.20627570152283%; recall_5 of 91.80327653884888%\n",
      "Score for GRU1: loss of 0.06729728728532791; accuracy of 98.20627570152283%; recall_6 of 88.52459192276001%\n",
      "Score for GRU2: loss of 0.07106711715459824; accuracy of 97.98206090927124%; recall_7 of 86.8852436542511%\n",
      "Training for fold 3 ...\n",
      "Score for LSTM1: loss of 0.034061234444379807; accuracy of 98.87892603874207%; recall_8 of 98.36065769195557%\n",
      "Score for LSTM2: loss of 0.038906991481781006; accuracy of 98.65471124649048%; recall_9 of 98.36065769195557%\n",
      "Score for GRU1: loss of 0.020713651552796364; accuracy of 99.55157041549683%; recall_10 of 96.72130942344666%\n",
      "Score for GRU2: loss of 0.016222044825553894; accuracy of 99.55157041549683%; recall_11 of 96.72130942344666%\n",
      "Training for fold 4 ...\n",
      "Score for LSTM1: loss of 0.0389670729637146; accuracy of 98.87892603874207%; recall_12 of 91.80327653884888%\n",
      "Score for LSTM2: loss of 0.04667122662067413; accuracy of 98.65471124649048%; recall_13 of 90.16393423080444%\n",
      "Score for GRU1: loss of 0.03848167136311531; accuracy of 98.87892603874207%; recall_14 of 91.80327653884888%\n",
      "Score for GRU2: loss of 0.038204483687877655; accuracy of 99.10314083099365%; recall_15 of 95.08196711540222%\n",
      "Training for fold 5 ...\n",
      "Score for LSTM1: loss of 0.021731577813625336; accuracy of 99.55157041549683%; recall_16 of 98.36065769195557%\n",
      "Score for LSTM2: loss of 0.023791611194610596; accuracy of 99.10314083099365%; recall_17 of 93.44262480735779%\n",
      "Score for GRU1: loss of 0.014892447739839554; accuracy of 99.77578520774841%; recall_18 of 98.36065769195557%\n",
      "Score for GRU2: loss of 0.021352045238018036; accuracy of 99.32735562324524%; recall_19 of 96.72130942344666%\n",
      "Training for fold 6 ...\n",
      "Score for LSTM1: loss of 0.04197917506098747; accuracy of 98.43049049377441%; recall_20 of 96.72130942344666%\n",
      "Score for LSTM2: loss of 0.011900386773049831; accuracy of 99.77578520774841%; recall_21 of 98.36065769195557%\n",
      "Score for GRU1: loss of 0.008798022754490376; accuracy of 99.77578520774841%; recall_22 of 98.36065769195557%\n",
      "Score for GRU2: loss of 0.01572391204535961; accuracy of 99.55157041549683%; recall_23 of 96.72130942344666%\n",
      "Training for fold 7 ...\n",
      "Score for LSTM1: loss of 0.005200767889618874; accuracy of 99.77578520774841%; recall_24 of 98.36065769195557%\n",
      "Score for LSTM2: loss of 0.0033879282418638468; accuracy of 100.0%; recall_25 of 100.0%\n",
      "Score for GRU1: loss of 0.008279411122202873; accuracy of 99.77578520774841%; recall_26 of 98.36065769195557%\n",
      "Score for GRU2: loss of 0.0065319431014359; accuracy of 99.77578520774841%; recall_27 of 98.36065769195557%\n",
      "Training for fold 8 ...\n",
      "Score for LSTM1: loss of 0.0033023308496922255; accuracy of 100.0%; recall_28 of 100.0%\n",
      "Score for LSTM2: loss of 0.03550400957465172; accuracy of 99.10112619400024%; recall_29 of 100.0%\n",
      "Score for GRU1: loss of 0.0009695496410131454; accuracy of 100.0%; recall_30 of 100.0%\n",
      "Score for GRU2: loss of 0.0026617886032909155; accuracy of 99.77527856826782%; recall_31 of 98.33333492279053%\n",
      "Training for fold 9 ...\n",
      "Score for LSTM1: loss of 0.0023162553552538157; accuracy of 100.0%; recall_32 of 100.0%\n",
      "Score for LSTM2: loss of 0.0007485317764803767; accuracy of 100.0%; recall_33 of 100.0%\n",
      "Score for GRU1: loss of 0.0014662707690149546; accuracy of 100.0%; recall_34 of 100.0%\n",
      "Score for GRU2: loss of 0.0005780075443908572; accuracy of 100.0%; recall_35 of 100.0%\n",
      "Training for fold 10 ...\n",
      "Score for LSTM1: loss of 0.001569276093505323; accuracy of 100.0%; recall_36 of 100.0%\n",
      "Score for LSTM2: loss of 0.0005341380601748824; accuracy of 100.0%; recall_37 of 100.0%\n",
      "Score for GRU1: loss of 0.0005736632156185806; accuracy of 100.0%; recall_38 of 100.0%\n",
      "Score for GRU2: loss of 0.0018305513076484203; accuracy of 100.0%; recall_39 of 100.0%\n",
      "CPU times: user 1h 47min 20s, sys: 18min 48s, total: 2h 6min 8s\n",
      "Wall time: 46min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc_per_fold1 = []\n",
    "recall_per_fold1 = []\n",
    "loss_per_fold1 = []\n",
    "mean_tpr1 = 0.0\n",
    "\n",
    "acc_per_fold2 = []\n",
    "recall_per_fold2 = []\n",
    "loss_per_fold2 = []\n",
    "mean_tpr2 = 0.0\n",
    "\n",
    "acc_per_fold3 = []\n",
    "recall_per_fold3 = []\n",
    "loss_per_fold3 = []\n",
    "mean_tpr3 = 0.0\n",
    "\n",
    "acc_per_fold4 = []\n",
    "recall_per_fold4 = []\n",
    "loss_per_fold4 = []\n",
    "mean_tpr4 = 0.0\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "\n",
    "    # Compile the model\n",
    "    lstm1.compile(loss='binary_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy', keras.metrics.Recall()])\n",
    "    lstm2.compile(loss='binary_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy', keras.metrics.Recall()])\n",
    "    gru1.compile(loss='binary_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy', keras.metrics.Recall()])\n",
    "    gru2.compile(loss='binary_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy', keras.metrics.Recall()])\n",
    "\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {k+1} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history1 = lstm1.fit(X_train[train], y_train[train], epochs=3, batch_size=64, validation_data=(X_train[test], y_train[test],), verbose=0)\n",
    "    history2 = lstm2.fit(X_train[train], y_train[train], epochs=3, batch_size=64, validation_data=(X_train[test], y_train[test],), verbose=0)\n",
    "    history3 = gru1.fit(X_train[train], y_train[train], epochs=3, batch_size=64, validation_data=(X_train[test], y_train[test],), verbose=0)\n",
    "    history4 = gru2.fit(X_train[train], y_train[train], epochs=3, batch_size=64, validation_data=(X_train[test], y_train[test],), verbose=0)\n",
    "\n",
    "    mean_tpr1 = roc(lstm1, test, train, mean_tpr1)\n",
    "    mean_tpr2 = roc(lstm2, test, train, mean_tpr2)\n",
    "    mean_tpr3 = roc(gru1, test, train, mean_tpr3)\n",
    "    mean_tpr4 = roc(gru2, test, train, mean_tpr4)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores1 = lstm1.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "    scores2 = lstm2.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "    scores3 = gru1.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "    scores4 = gru2.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "\n",
    "    print(f'Score for LSTM1: {lstm1.metrics_names[0]} of {scores1[0]}; {lstm1.metrics_names[1]} of {scores1[1]*100}%; {lstm1.metrics_names[2]} of {scores1[2]*100}%')\n",
    "    print(f'Score for LSTM2: {lstm2.metrics_names[0]} of {scores2[0]}; {lstm2.metrics_names[1]} of {scores2[1]*100}%; {lstm2.metrics_names[2]} of {scores2[2]*100}%')\n",
    "    print(f'Score for GRU1: {gru1.metrics_names[0]} of {scores3[0]}; {gru1.metrics_names[1]} of {scores3[1]*100}%; {gru1.metrics_names[2]} of {scores3[2]*100}%')\n",
    "    print(f'Score for GRU2: {gru2.metrics_names[0]} of {scores4[0]}; {gru2.metrics_names[1]} of {scores4[1]*100}%; {gru2.metrics_names[2]} of {scores4[2]*100}%')\n",
    "\n",
    "    loss_per_fold1.append(scores1[0])\n",
    "    acc_per_fold1.append(scores1[1] * 100)\n",
    "    recall_per_fold1.append(scores1[2]*100)\n",
    "    loss_per_fold2.append(scores2[0])\n",
    "    acc_per_fold2.append(scores2[1] * 100)\n",
    "    recall_per_fold2.append(scores2[2]*100)\n",
    "    loss_per_fold3.append(scores3[0])\n",
    "    acc_per_fold3.append(scores3[1] * 100)\n",
    "    recall_per_fold3.append(scores3[2]*100)\n",
    "    loss_per_fold4.append(scores4[0])\n",
    "    acc_per_fold4.append(scores4[1] * 100)\n",
    "    recall_per_fold4.append(scores4[2]*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f568fc2",
   "metadata": {},
   "source": [
    "**Discuss performance of models. Visualize the results of all the RNNs you trained.  Use proper statistical comparison techniques to determine which method(s) is (are) superior.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f74a9f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAt2klEQVR4nO3deXxU5dn/8c81M9nYgmWJaFSQIAmBJEBYFRqwLOJjxRXBn6BSqbLUR9sKdtNa+ihuD3WpSF0QylOsiopUcI+4IYuELWFVFBAREEICZJu5f3/MzDGTTJJJmElykuv9euWVnDlnztz3BL5z5z7nXEeMMSillLI/R0M3QCmlVHhooCulVBOhga6UUk2EBrpSSjURGuhKKdVEuBrqhdu3b286d+5cp+eeOHGCli1bhrdBjZz2uXnQPjcPp9Pn9evXHzbGdAi2rsECvXPnzqxbt65Oz83OziYrKyu8DWrktM/Ng/a5eTidPovI11Wt0ykXpZRqIjTQlVKqidBAV0qpJkIDXSmlmggNdKWUaiJqDHQReU5EvheRLVWsFxF5TER2icgmEekT/mYqpZSqSSgj9AXA6GrWXwJ0831NAZ46/WYppZSqrRrPQzfGrBKRztVscjmw0Hjr8K4WkbYi0skYcyBcjVS1d/jI93y7P/jpqmWmjKNFR/ih+AcKio9R5wLKZUWIu8RadBUWE3PsBDHHTuAoLqvrXi3Hjh1l2YeLQtjSIGXFSFkR4i6GMJWEdpS4ickvIfp4Ma5Tp98fi8eNeNxg3FD+3TcQ7fHw2X1S7dMNYIzBDZQJlIn3Zztb8ZeGbkH9KjgjGrJywr7fcFxYdDawt9zyPt9jlQJdRKbgHcWTkJBAdnZ2nV6wsLCwzs8NB2MMpzynOOE5UWldsdtQWFr986W0lOjCE4jbg8OUElVaiCnOxxQdx1FynFMUU+gooVBKKTYeygyUlnl49aPZnHSWcNJZilt8/4UNnFHg4bzv3Jz3nZuOR93EF3poWQxRVbx+FBAHnHU6b4JSqs6+cZdEJMPCEejBhhNBh0jGmPnAfIDMzExT1yulqrvKyp2fz7drV5H3+QrKik9VWl9c5uaHkyfILyrgZNlJMKVEUUq0KaFFsYf4AmhTaIipIpQ9gFu8nW4VZH0roF0V7XZ4oO0JaFO5WWFX4oSTccF/EQI4MDiMd86t+vFg1SruuzQaTraEU62gtKpPkwhxi5MyvF+mzj0KVOYUCls6KWzl4GSso+5vVAWluCgmhmKi8ZTbqcvpQIybFrHROCX4izlEiHY5iHY5iHVG0drZkjbOlrRwxIancQ3g8KFDtO8Q9Er2JuuHE8X8vwhcHRuOQN8HnFNuORH4Ngz7rZXj77/P3jl/xfG196XPqWH7huR2GI63BLcD/ClhAHz/iR2I98uAiCB4/ypwOhw4EZwIUi4ITAsXpWe3pjSxNY4z23B2xzM4s21rnI4InMQkAmd0gcRM6JACzshVj9BLwpuH5trnSAjH/8ZlwHQRWQIMAPLrc/7cU1LClvvuIurlt3DgHZnuORNK25UR5/IEfU6MMbQ0hpYeDy4clLbsRGnrRErbJuA+ow3uM9pg4mKCPjfK4aKNqzWxzsD1LoeDNrEuWsQ4A8I2gAiuM+Jxtm2DOJ3Qoj206ggOZ439bI7/6JVStVNjoIvIv4AsoL2I7APuwTc9a4yZB7wJjAF2ASeBmyLV2IoO7tvBtknj6Li/iDIHvDoUOnQ7wWUnTrGmtD95nk7Wtm3iokhPbEuvxDa0aNMeWneCNp2gQzJEN69Kb0qppimUs1zG17DeANPC1qJaWPfo7Zy/v4hD8fD18FNcGR3DewWXcv/ZV3D+eefRuV1LzmwTy5nxsXRp3xKnI0yToEop1Qg1WPnccDh59BgAX18Qw+qEP3LeJT/jVxd0QKo4oKSUUk2ZrQPdU+abI49ryxO3j9cgV0o1a7au5SIeb6C7ol0a5kqpZs/WgY7HdyZ0CGeJKKVUU2frQPeP0HFqoCullM0D3TtCFw10pZRqIoHusPWxXaWUCgt7B7rbN4fu0hG6UkrZO9CNf8pFR+hKKWXvQPdPubjqubSfUko1QjYPdN93l47QlVLK5oHun3LREbpSStk60B065aKUUhZbB7r4TnJxaqArpZS9A90/QndERTdwS5RSquHZOtD9B0UdLg10pZRqEoHu1BG6UkrZO9Ad/jn0qOD3/1RKqebE3oHum0PXEbpSStk+0H3fo2MbtiFKKdUINIlAj4rWEbpSSjWJQHdF6QhdKaXsHei+g6JRMS0atiFKKdUI2DvQ/act6hy6Uko1jUCPjo1r2IYopVQj0CQC3aVTLkop1TQCPUYDXSml7B3oTv9BUZ1yUUopewe6NUKPbdmwDVFKqUbA1oHudHu/R2ugK6WUfQPdXVZqNT4mRqdclFIqpEAXkdEisl1EdonIrCDr40XkDRHZKCJbReSm8Dc1UOmpEwCUOcDlckb65ZRSqtGrMdBFxAk8CVwC9ADGi0iPCptNA3KNMelAFvCIiES0wEpRsTfQ3Q4QkUi+lFJK2UIoI/T+wC5jzJfGmBJgCXB5hW0M0Fq8ydoK+AEoC2tLKyj2jdA9tp00Ukqp8HKFsM3ZwN5yy/uAARW2eQJYBnwLtAbGGWM8FXckIlOAKQAJCQlkZ2fXoclQWFjI56s/oRveEXpd92MnhYWFzaKf5Wmfmwftc/iEEujB5jNMheVRQA4wHOgKvCMiHxljjgc8yZj5wHyAzMxMk5WVVdv2At4AP69zO4rwjtDruh87yc7Obhb9LE/73Dxon8MnlAmLfcA55ZYT8Y7Ey7sJWGq8dgFfAcnhaWJwxcWnAPDo9LlSSgGhBfpaoJuIdPEd6LwO7/RKed8AFwOISALQHfgynA2tqKzEF+g6h66UUkAIUy7GmDIRmQ68BTiB54wxW0XkVt/6ecBfgAUishnvFM1MY8zhCLabsuJTONFAV0opv1Dm0DHGvAm8WeGxeeV+/hYYGd6mVa+0pJgYNNCVUsrPtnFYVnQS0Dl0pZTys2+glxYBYGzbA6WUCi/bxmFZaQmgUy5KKeVn2zj0lPgDXedclFIKbBzobt+Ui47QlVLKy7Zx6PZNuRgdoCulFGDjQPeUlXq/65SLUkoBdg70Um+g61kuSinlZds49Lh9Uy627YFSSoWXbePQU+Ytt+7Rm1sopRRg40A3Zf4pFw10pZQCGwe6RwNdKaUC2DbQjds75aJz6Eop5WXbODS+OXQjtu2CUkqFlW3T0Ap0ZwM3RCmlGgnbBjoeNwDGYd8uKKVUONk2DY3bH+h6UFQppcDGgY4GulJKBbBvoPumXNApF6WUAuwc6G4PoHPoSinlZ9809AU6OuWilFKAnQNdp1yUUiqAfdPQ45tyceqJ6EopBTYOdLGmXGzbBaWUCiv7pqE/0HWErpRSgI0DXYzx/qCBrpRSgJ0D3Rqh27YLSikVVrZNwx9H6K6GbYhSSjUStg103N5AF4dOuSilFNg40P0jdHHpCF0ppSDEQBeR0SKyXUR2icisKrbJEpEcEdkqIh+Gt5lBXs/jC3SdclFKKQBqTEMRcQJPAiOAfcBaEVlmjMktt01b4O/AaGPMNyLSMULt/bFdGuhKKRUglBF6f2CXMeZLY0wJsAS4vMI2E4ClxphvAIwx34e3mZVZge7SOXSllIIQRujA2cDecsv7gAEVtrkAiBKRbKA18DdjzMKKOxKRKcAUgISEBLKzs+vQZCgsLLQCveDEqTrvx04KCwubRT/L0z43D9rn8Akl0IOVMzRB9tMXuBiIAz4TkdXGmB0BTzJmPjAfIDMz02RlZdW6wQDZ2dkU+AK97U/aUdf92El2dnaz6Gd52ufmQfscPqEE+j7gnHLLicC3QbY5bIw5AZwQkVVAOrCDCBHfR4rDFR2pl1BKKVsJZQ59LdBNRLqISDRwHbCswjavA0NExCUiLfBOyeSFt6mBHL4LRcUVFcmXUUop26hxhG6MKROR6cBbgBN4zhizVURu9a2fZ4zJE5GVwCbAAzxjjNkSyYb759Ad0TpCV0opCG3KBWPMm8CbFR6bV2H5IeCh8DWteg6r2KKO0JVSCux8pai/HLqO0JVSCrBxoDt8l/67omIbuCVKKdU42DfQ/VMuUTEN2xCllGokbBvo/ikXp065KKUUYONAd/jOQ4/SKRellALsHOj+EXpMXMM2RCmlGgnbB3pUjI7QlVIKbBzoTl+gu6J1hK6UUmDjQP9xhK6BrpRS0AQCPTqmRcM2RCmlGgn7BrrvLJfouJYN2xCllGokbBvo/jn0GB2hK6UUYONA90+5xMS1atiGKKVUI2HLQDceDy7/HHqsHhRVSimwaaB73CXe7wLR0VrLRSmlwKaBXlbqDXS3A0SC3fJUKaWaH1sGuqe02Pvdlq1XSqnIsGUkusu8ge7WwblSSllsGuhFgI7QlVKqPFtGoqfMd1DUlq1XSqnIsGUkaqArpVRltoxEf6C7bdl6pZSKDFtGoo7QlVKqMltGoqes1Pvdlq1XSqnIsGUkGrc30I2etqiUUhZbB7qO0JVS6ke2jERjzaHrEF0ppfzsGejuMsBbnEsppZSXrQPd2LL1SikVGfaMRP8I3Z6tV0qpiLBlJBqP/ywXnXNRSim/kAJdREaLyHYR2SUis6rZrp+IuEXk6vA1sTJT5vZ+t+XHkVJKRUaNkSgiTuBJ4BKgBzBeRHpUsd0c4K1wN7ISj3/KRUfoSinlF8oYtz+wyxjzpTGmBFgCXB5kuxnAK8D3YWxfcG4doSulVEWuELY5G9hbbnkfMKD8BiJyNnAFMBzoV9WORGQKMAUgISGB7OzsWjbXy13qu7BIqPM+7KawsLDZ9NVP+9w8aJ/DJ5RADzavYSoszwVmGmPc1d3j0xgzH5gPkJmZabKyskJrZQV7lj3q/cHpoK77sJvs7Oxm01c/7XPzoH0On1ACfR9wTrnlRODbCttkAkt8Yd4eGCMiZcaY18LRyEqMf8pF59CVUsovlEBfC3QTkS7AfuA6YEL5DYwxXfw/i8gCYHnEwhwQtwa6UkpVVGOgG2PKRGQ63rNXnMBzxpitInKrb/28CLexMo/H2zY9D10ppSyhjNAxxrwJvFnhsaBBboy58fSbVQOPjtCVUqoie5745x+hO+zZfKWUigR7JqJ/hO7UEbpSSvnZMtDF7fH9YMvmK6VURNgyEcXjPQ3eOG3ZfKWUigh7JqLxjdB1Dl0ppSy2TETxaKArpVRFtkxEh065KKVUJfZMRP8IXQNdKaUstkxE/0FRHM6GbYhSSjUi9gx04wt0pwa6Ukr52TPQfSN00UBXSimLrQNdR+hKKfUjWwe6OEKqLaaUUs2CPQPdN4cuLh2hK6WUny0D3WFNuegIXSml/GyZiNaUiyuqgVuiIqW0tJRWrVqRl5fX0E2pV/Hx8drnZiCUPsfGxpKYmEhUVOg5Z89At05Dt2XzVQj27dtHQkICiYmJVHfj8aamoKCA1q1bN3Qz6pX2uTJjDEeOHGHfvn106dKlyu0qsvWUiyNKA72pKioqIj4+vlmFuVJ+IkK7du0oKiqq1fNsGejir83l1CmXpkzDXDVndfn3b89A9025SFR0wzZEKaUaEVsGujXlogdFVQS1atWq0mPbt28nKyuLjIwMUlJSmDJlCm+99RYZGRlkZGTQqlUrunfvTkZGBhMnTiQ7OxsR4dlnn7X2sWHDBkSEhx9+GICXXnqJ1NRUHA4HX3zxRdC27NmzBxHhj3/8o/XY4cOHiYqKYvr06WHueaCsrCy6d+9Oeno6/fr1Iycnx1qXn5/PxIkT6dq1K127dmXixInk5+db63fs2MGYMWNISkoiJSWFa6+9loMHD1Z6jQMHDvBf//VfEe3H6TDG8Ktf/YqkpCTS0tKq/D29//779OnTh549ezJp0iTKysoAOHr0KFdccQVpaWn079+f3NxcAEpKShg6dKi13emyZaD7p1ycLh2hq/r1q1/9ijvuuIOcnBzy8vKYMWMGo0aNIicnh5ycHDIzM1m8eDE5OTksXLgQgF69evHiiy9a+1iyZAnp6enWcs+ePVm6dClDhw6t9rXPP/98li9fbi37Pwjqw+LFi9m4cSNTp07lt7/9rfX45MmTOf/889m9eze7d++mS5cu/OIXvwC8x0EuvfRSbrvtNnbt2kVeXh633XYbhw4dqrT/Rx99lFtuuSXk9rjd7tPvVC2sWLGCnTt3snPnTubPn89tt91WaRuPx8OkSZNYsmQJW7Zs4bzzzuOFF14A4H/+53/IyMhg06ZNLFy4kJkzZwIQHR3NxRdfHPDv43TY8qiiw3+WS1RMwzZE1YvOs/4Tkf3ueeDSWj/nwIEDJCYmWsu9evWq8Tnnnnsux48f5+DBg3Ts2JGVK1cyZswYa31KSkpIrx0XF0dKSgrr1q0jMzOTF198kWuvvZZvv/0WgEOHDnHrrbfyzTffADB37lwuvPBC1qxZw3//939z6tQp4uLieP755+nevTsLFixg2bJlnDx5kt27d3PFFVfw4IMPVtuGQYMG8dBDDwGwa9cu1q9fHxBGf/rTn0hKSmL37t18+OGHDBo0iMsuu8xaP2zYsKD7feWVV5g9ezbg/Wvkhhtu4MSJEwA88cQTDB48mOzsbP785z/TqVMncnJy2Lx5M7NmzSI7O5vi4mKmTZvGL3/5SwoLC7n88ss5evQopaWlzJ49m8svvzyk97gqr7/+OhMnTkREGDhwIMeOHePAgQN06tTJ2ubIkSPExMRwwQUXADBixAjuv/9+Jk+eTG5uLnfffTcAycnJfP311xw8eJCEhATGjh3L3XffzfXXX39abQS7BrpvysWpc+iqnt1xxx0MHz6cwYMHM3LkSG666Sbatm1b4/OuvvpqXnrpJXr37k2fPn2IianbYOS6665jyZIlnHnmmTidTs466ywr0G+//XbuuOMOLrroIr755htGjRpFXl4eycnJrFq1CpfLxbvvvsvvfvc7XnnlFQBycnLYsGEDMTExdO/enRkzZnDOOedU+forV65k7NixAOTm5pKRkYGzXE0lp9NJRkYGW7duZcuWLfTt27fGPu3Zs4czzjjDek86duzIO++8Q2xsLDt37mT8+PGsW7cOgDVr1rBlyxa6dOnC/PnziY+PZ+3atRQXF3PhhRcycuRIzjnnHF599VXatGnD4cOHGThwID//+c8rHWQcN24c27dvr9SeO++8k4kTJwY8tn///oD3JTExkf379wcEevv27SktLbU+cF9++WX27t0LQHp6OkuXLuWiiy5izZo17N271zo1t2fPnqxdu7bG9ykUNg1073cN9OahLiPpSLnpppsYNWoUK1eu5PXXX+fpp59m48aNNQb0tddey7hx49i2bRvjx4/n008/rdPrjx49mj/+8Y8kJCQwbty4gHXvvvuuNTcLcPz4cQoKCsjPz2fSpEns3LkTEaG0tNTa5uKLLyY+Ph6AHj168PXXXwcN9Ouvv54TJ07gdrut+WNjTNAzMap6vCoHDx6kQ4cO1nJpaSnTp08nJycHp9PJjh07rHX9+/e3zst+++232bRpEy+//DLgnc/fuXMniYmJ/O53v2PVqlU4HA7279/PwYMHOfPMMwNetzbTHMZfsrucin0UEZYsWcIdd9xBcXExI0eOxOXyRuysWbO4/fbbycjIoFevXqSlpVnrnE4n0dHRYTkf396BHq1TLqr+nXXWWdx8883cfPPN9OzZM6SR6JlnnklUVBTvvPMOf/vb3+oc6NHR0fTt25dHHnmErVu38sYbb1jrPB4Pn332GXFxcQHPmTFjBsOGDePVV19lz549ZGVlWevKfxA5nc4qD84tXryY9PR0Zs2axbRp01i6dCmpqals2LABj8eDw3d/X4/Hw8aNG0lJSeH777/nww8/rLFPsbGxAedb/+///i8JCQls3LgRj8dDbGysta5ly5bWz8YYHn/8cUaNGhWwvwULFnDo0CHWr19PVFQUnTt3Dno+d21G6ImJidZoG7wXvp111lmVnjto0CA++ugjwPuB4/8watOmDc8//7zV7s6dOwdcMFRcXBzQz7qy9UFRV3Rc9RsqFWYrV660RrjfffcdR44c4eyzzw7puffddx9z5swJmKKoi1//+tfMmTOHdu3aBTw+cuRInnjiCWvZfzZKfn6+1cYFCxbU+XWjoqKYPXs2q1evJi8vj6SkJHr37m3NfQPMnj2bPn36kJSUxIQJE/j000/5z39+PAaycuVKNm/eHLDfpKQk9uzZYy3n5+fTqVMnHA4HixYtqvIA6KhRo3jqqaes38eOHTs4ceIE+fn5dOzYkaioKD744AO+/vrroM9/8cUXrYPZ5b8qhjnAz3/+cxYuXIgxhtWrVxMfHx8w3eL3/fffA96AnjNnDrfeeisAx44do6SkBIBnnnmGwYMH06ZNG8A7996hQ4daXeJfFVsGuv+gqEtH6CqCTp48SWJiovX16KOP8vbbb9OzZ0/S09MZNWoUDz30UKU/5asyePBga/65vFdffZXExEQ+++wzrrnmmkojzopSU1OZNGlSpccfe+wx1q1bR1paGj169GDevHkA3HXXXdx9991ceOGFp312SFxcHL/+9a+tUy6fffZZduzYQVJSEl27dmXHjh3WKZpxcXEsX76cxx9/nG7dutGjRw8WLFhAx44dA/bZsmVLunbtyq5duwCYOnUqL7zwAgMHDmTHjh0Bo/LyfvGLX9CjRw/rNMFf/vKXlJWVcf3111vz2IsXLyY5Ofm0+gwwZswYzj//fJKSkrjlllv4+9//HrDOfxzjoYceIiUlhbS0NC677DKGDx8OQF5eHqmpqSQnJ7NixQrmzJljPf+DDz4IOEh+OiTY3FB9yMzMNP4DHbX1cf8U2h2HU/P+Sp+sK8PcssYpOzs74E/lpi4vL4/ExESt8dEMFBQU8O6777J+/fqA0X5TVv73fOWVV3L//ffTvXv3Stvl5eVVOgtKRNYbYzKD7dfWc+iuGJ1yUaopuOKKKzhy5EhDN6PelZSUMHbs2KBhXhchTbmIyGgR2S4iu0RkVpD114vIJt/XpyKSHmw/4eIP9BgNdKWaDP8FSc1JdHR00Dn7uqox0EXECTwJXAL0AMaLSI8Km30F/NQYkwb8BZgfthYGYc2ha6ArpZQllBF6f2CXMeZLY0wJsAQIuOzKGPOpMeaob3E1kEgEOX0j9OiY4AdLlFKqOQplDv1sYG+55X3AgGq2nwysCLZCRKYAUwASEhLIzs4OrZUVxPsCfeOWLezed7hO+7CbwsLCOr9fdhQfH4/b7aagoKChm1KvtM/NQ6h9LioqqtX/+1ACPdglX0FPjRGRYXgD/aJg640x8/FNx2RmZpq6nrWx0RfoFw35KW3bVT4XtClqjme5OJ3OZnnGh/a56Qu1z7GxsfTu3Tvk/YYy5bIPKH8tcCLwbcWNRCQNeAa43BgT0cPVLv+US6xOuajIqa/yub/97W9JTk4mLS2NCRMmcOzYsUqvq+VzG1ZTKp+7FugmIl1EJBq4DlhWfgMRORdYCtxgjNkRZB9hU1ZaYh0UjY5uEcmXUqqSSJTPHTFiBFu2bGHTpk0kJSVx//33B31tLZ/7Iy2fG1yNUy7GmDIRmQ68BTiB54wxW0XkVt/6ecCfgHbA330Fa8qqOvH9dJUUnwKgzAEuvado83BvfIT2m1/zNhVEonzuyJEjrZ/79esXcKl8eVo+V8vn1iSkRDTGvAm8WeGxeeV+/gVQLyeRFp8qBMBjy6IFyu4iXT530aJF1f7H1vK5Wj63OrYb4pacOgmAWwO9+ajDSDpSIlk+969//Ssul6vaQNfyuVo+tzq2C/TiEm+ge/SG8KqBRKJ87gsvvMDy5ct57bXXqg1DLZ+r5XOrY7txblmRL9Bt13LVFESifO7KlSuZM2cOy5Yto0WLmg/0a/lcLy2fW5ntYtF/UFQDXUVafZXPnT59OgUFBYwYMYILL7zQCoGqaPlcLy2fW5ntyudu/uw/uG76DUdbw+C1eRFoWePUHC8s0vK5zYOWz23G5XPLiopwoXPoSjUlWj63HsvnNialpTrlolRTpOVzT5/tYrHMd7RaA10ppQLZLhbLSjXQlVIqGNvFYllJMaBz6EopVZHtAt1T6gt0hya6UkqVZ7tAd/suIjC2a7mym4MHDzJhwgTOP/98+vbty6BBg3j11VcB72mk8fHx9O7dm+TkZH7zm99Yz7v33nut87T9OnfuzOHD3pux3HzzzXTs2JGePXtW+dr33nsvImKdmw3eKyhFhLqc7huqPXv2EBcXR0ZGBj169GDixIkBpQI+/vhj+vfvT3JyMsnJycyfH3i3yYULF9KzZ09SU1Pp0aNHpffBb+7cuVY1ysboq6++YsCAAXTr1o1x48ZZFwVVNHPmTHr27EnPnj0DSglUVUZ3+fLl3HPPPRFrt+1i8ccRegM3RDVpxhjGjh3L0KFD+fLLL1m/fj1Llixh37591jZDhgxhw4YNbNiwgeXLl/PJJ5+EtO8bb7yRlStX1rhdr169WLJkibX88ssv06NHxdv5hl/Xrl2taob79u3j3//+N+C9MnbChAnMmzePbdu28fHHH/P0009bV4KuWLGCuXPn8vbbb7N161a++OILq05MeWVlZTz33HNMmDAh5DaFq154qGbOnMkdd9zBzp07OeOMMwLq2fv95z//4YsvviAnJ4fPP/+chx56iOPHj1dbRvfSSy+1KlxGgu3OQ3eXeT8pjU65NBu9Xqi5RG1dbJ60ucp177//PtHR0QFXbZ533nnMmDGj0rb+Ee3+/ftDet2hQ4cGXOpelbFjx/L666/zhz/8gS+//JL4+PiAy8Pffvtt7rnnHoqLi+natSvPP/88rVq14r777uONN97g1KlTDB48mKeffhoRISsriwEDBvDBBx9w7Ngxnn32WYYMGVLl6zudTvr372/168knn+TGG2+kT58+gLe64IMPPsi9997LpZdeyv3338/DDz9s1TiJjY0NWuPcP3r1F6dasGABCxcupKSkhKSkJBYtWkSLFi248cYb+clPfsKGDRvo06cPU6dOZdq0aRw6dIgWLVrwj3/8g+TkZN544w1mz55NSUkJ7dq1Y/HixSQkJIT0uwjGGMP777/P//3f/wEwadIk7r333ko10HNzc/npT3+Ky+XC5XKRnp7OypUrGTZsWJVldP2/h5UrVwa92vd02W6c6ynz/vmnB0VVJG3dutUKrpocPXqUnTt3MnTo0LC2oU2bNpxzzjls2bKFf/3rXwHVFQ8fPszs2bN59913+eKLL8jMzOTRRx8FvKUE1q5dy5YtWzh16lTATTHKyspYs2YNc+fO5c9//nO1r19UVMTnn3/O6NGjAe97UrEIWWZmJlu3bgUIuVzuJ598ErDdZZddxtq1a62iXuVHwzt27ODdd9/lkUceYcqUKTz++OOsX7+ehx9+mKlTpwJw0UUXsXr1ajZs2MB1110XtKb79u3brbtKVfyqeIeoI0eO0LZtW+sDx18qt6L09HRWrFjByZMnOXz4MB988AF79+4NKKMLBJTR9b9nwapthoPtRuj+QNc59OajupF0fZk2bRoff/wx0dHRVu3qjz76iLS0NLZv386sWbOsmi5VVUusTUlZP3/987feeov33nvPqti3evVqcnNzufDCCwHvFYeDBg0CvLVBHnzwQU6ePMkPP/xAamqqdZOJK6+8EoC+fftW+VfC7t27ycjIYOfOnVx99dWkpaUBVZfFrW2/Dhw4EHA5e15eHjfccAPHjh2jsLAwoHriNddcg9PppLCwkE8//ZRrrrnGWldc7J1+3bdvH+PGjePAgQOUlJQEVDH06969e8Ct86oTSqlc8BZDW7t2LYMHD6ZDhw4MGjQIl8tVbRld8NZ7/+6770JqS23ZLhaNby5Np1xUJKWmpgbcN/LJJ5/kvffeC7h92pAhQ9i0aRObN2/mqaeesgKjXbt2HD16NGB/BQUFId0Io6LLLruMRYsWce6551rV+cAbOiNGjLAqBObm5vLss89SVFTE1KlTefnll9m8eTO33HJLQOlYf7nc6krl+ufQd+3axerVq1m2bJn1nlQ8ILt+/XprXj81NZX169fX2Ke4uLiANt1222088cQTbN68mXvuuSdgnb8wl8fjoW3btgFVEfPyvLWcZsyYwfTp09m8eTNPP/100FK5tRmht2/fnmPHjlnvT1WlcgF+//vfk5OTwzvvvIMxhm7dugE/ltFds2YNQ4cOtR4H718+4SiVG4ztAt3j9s6h62mLKpKGDx9OUVERTz31lPVYVQeyLrjgAu6++26rgt7QoUNZtmwZBQUFACxdupT09PRKZXNDERcXx5w5c/j9738f8PjAgQP55JNPrLNgTp48yY4dO6wwa9++PYWFhdbNH+qiU6dOPPDAA9Y9TqdNm8aCBQusD64jR44wc+ZM7rrrLgDuvvtu7rrrLmv0WVxczGOPPVZpvykpKQFn7xQUFNCpUydKS0tZvHhx0La0adOGLl268NJLLwHeD7SNGzcCgeWB/QcfK/KP0IN9VfygFRGGDRtmvXcvvPBC0FvYud1uq/7Mpk2b2LRpk3U7warK6IJ3GilSB7dtF+jGf9piHf58VSpUIsJrr73Ghx9+SJcuXejfvz+TJk0KKHta3q233sqqVav46quvSEtLY/r06Vx00UVkZGQwb948nnnmGWvb8ePHM2jQILZv305iYmLQMyjKu+666yrN53fo0IEFCxYwfvx40tLSGDhwINu2baNt27bccsst9OrVi7Fjx9KvX7/Teh/Gjh3LyZMn+eijj+jUqRP//Oc/ueWWW0hOTmbw4MHcfPPN1nTOmDFjmDZtGj/72c9ITU2lb9++Qf8KuOSSS1i1apW1/Ic//IEBAwYwYsSIakvdLl68mGeffZb09HRSU1N5/fXXAe8pntdccw1Dhgyhffv2p9Vfvzlz5vDoo4+SlJTEkSNHmDx5MgDr1q2zas6UlpYyZMgQevTowZQpU/jnP/9pTa1UVUYXvFNiFW/KETbGmAb56tu3r6mLf//+WpPbPdm88vNedXq+XX3wwQcN3YR6lZuba44fP97Qzah3zaXPY8eONTt27DDGNJ8+G2PMd999Z4YPHx5yn3Nzcys9BqwzVeSq/Ubobp1DV8ruHnjgAQ4cONDQzah333zzDY888kjE9m+7s1yM744rGuhK2Vf37t3DVgPcTvxTYP7jK+FmuxE61gjdfk1XSqlIsl0q6ghdKaWCs12g47/JrQa6UkoFsF+ge/wjdPs1XSmlIsl2qWjcHu8PTh2hq8iKRPncvXv3MmzYMFJSUkhNTeVvf/tb0NfW8rkNS8vn1hcdoat6YCJUPtflcvHII4+Ql5fH6tWrefLJJ8nNzQ26rZbPDXxOfbJr+VzbpaK4fYVzNNCbjbzklIh8VSdS5XM7depkXfXZunVrUlJSqnyev3wuYJXP7dChg7X+7bffZtCgQfTp04drrrmGwsJCAO677z769etHz549mTJlilVsKisri5kzZ9K/f38uuOACPvroo2rbGmr53AceeADgtMrn9uvXj/T0dK666ior7G688UbuvPNOhg0bxsyZM9m9ezejR4+mb9++DBkyhG3btgHwxhtvMGDAAHr37s3PfvYzDh48WG2/amJ85XOvvvpqwFs+97XXXqu0XfnyuS1btrTK5x45cqRS+dxXXnkFIKB8biTYLxU9vikXDXQVQfVRPnfPnj1s2LCBAQMGBF2v5XO1fG5t2e7CIvGf5VKHQkfKnlK25TV0E8JePrewsJCrrrqKuXPnBlRRrEjL52r53NoIaZgrIqNFZLuI7BKRWUHWi4g85lu/SURCG9rUhX+E7tQRuoqcSJbPLS0t5aqrruL666+3ArYqWj5Xy+fWRo2pKCJO4EngEqAHMF5EKh6ZuQTo5vuaAjxFhIjH9+mpI3QVQZEqn2uMYfLkyaSkpHDnnXfW2A4tn+ul5XNDE8owtz+wyxjzpTGmBFgCVOzd5cBCXzGw1UBbEekU5rZ6WSN0DXQVOZEqn/vJJ5+waNEi3n//fWuE+Oabb1bbFi2f66Xlc2smweaLAjYQuRoYbYz5hW/5BmCAMWZ6uW2WAw8YYz72Lb8HzDTGrKuwryl4R/AkJCT0LX9KVqi+/cdvScotJHfIuXS+8u5aP9+uCgsLadWqVUM3o97Ex8fTpUuXOt0Uws7cbnez6POECRO47777SEpKajZ9Bu/IffLkybz22msh9XnXrl3k5+cHPDZs2LD1xpjMYNuHclA02BGPip8CoWyDMWY+MB8gMzPTZGVlhfDyFWStJTs7mxvr8lwby87Opk7vl03l5eXhdDpp3bp1QzelXhUUFDSLPj/88MMcPHiQ1q1bN5s+A2zbto25c+eG/G87NjaW3r17h7z/UAJ9H3BOueVE4Ns6bKOUUoCWz23I8rlrgW4i0kVEooHrgGUVtlkGTPSd7TIQyDfGNL/q9SqsapoOVKopq8u//xpH6MaYMhGZDrwFOIHnjDFbReRW3/p5wJvAGGAXcBK4qdYtUaqc2NhY8vPzad26da3Pc1bK7owxHDlypNanN4Z0YZEx5k28oV3+sXnlfjbAtFq9slLVSExMZOPGjdbl7M1FJM9Rbqy0z8HFxsaSmJhYq/3a7kpR1TxERUVRWFhIZmbQg/lNVnZ2dq0OgjUF2ufw0cstlVKqidBAV0qpJkIDXSmlmogarxSN2AuLHAK+ruPT2wOHw9gcO9A+Nw/a5+bhdPp8njGmQ7AVDRbop0NE1lV16WtTpX1uHrTPzUOk+qxTLkop1URooCulVBNh10CfX/MmTY72uXnQPjcPEemzLefQlVJKVWbXEbpSSqkKNNCVUqqJaNSB3qhuTl1PQujz9b6+bhKRT0UkvSHaGU419bncdv1ExO27i5athdJnEckSkRwR2SoiH9Z3G8MthH/b8SLyhohs9PXZ1lVbReQ5EfleRLZUsT78+WWMaZRfeEv17gbOB6KBjUCPCtuMAVbgvWPSQODzhm53PfR5MHCG7+dLmkOfy233Pt6qn1c3dLvr4ffcFsgFzvUtd2zodtdDn38HzPH93AH4AYhu6LafRp+HAn2ALVWsD3t+NeYReuO6OXX9qLHPxphPjTFHfYur8d4dys5C+T0DzABeAb6vz8ZFSCh9ngAsNcZ8A2CMsXu/Q+mzAVqLtwB+K7yBXvku0zZhjFmFtw9VCXt+NeZAPxvYW255n++x2m5jJ7Xtz2S8n/B2VmOfReRs4ApgHk1DKL/nC4AzRCRbRNaLyMR6a11khNLnJ4AUvLev3Azcbozx1E/zGkTY86sx10MP282pbSTk/ojIMLyBflFEWxR5ofR5LjDTGONuIncvCqXPLqAvcDEQB3wmIquNMTsi3bgICaXPo4AcYDjQFXhHRD4yxhyPcNsaStjzqzEHenO8OXVI/RGRNOAZ4BJjzJF6alukhNLnTGCJL8zbA2NEpMwY81q9tDD8Qv23fdgYcwI4ISKrgHTAroEeSp9vAh4w3gnmXSLyFZAMrKmfJta7sOdXY55yaY43p66xzyJyLrAUuMHGo7XyauyzMaaLMaazMaYz8DIw1cZhDqH9234dGCIiLhFpAQwA8uq5neEUSp+/wfsXCSKSAHQHvqzXVtavsOdXox2hm2Z4c+oQ+/wnoB3wd9+ItczYuFJdiH1uUkLpszEmT0RWApsAD/CMMSbo6W92EOLv+S/AAhHZjHc6YqYxxrZldUXkX0AW0F5E9gH3AFEQufzSS/+VUqqJaMxTLkoppWpBA10ppZoIDXSllGoiNNCVUqqJ0EBXSqkmQgNdKaWaCA10pZRqIv4/rQoNffX9crgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "mean_tpr1a = mean_tpr1 / 10\n",
    "mean_auc1 = auc(mean_fpr, mean_tpr1a)\n",
    "plt.plot(mean_fpr,mean_tpr1a,lw=2,label='LSTM1 Mean ROC (area = %0.2f)' % (mean_auc1))\n",
    "\n",
    "mean_tpr2a = mean_tpr2 / 10\n",
    "mean_auc2 = auc(mean_fpr, mean_tpr2a)\n",
    "plt.plot(mean_fpr,mean_tpr2a,lw=2,label='LSTM2 Mean ROC (area = %0.2f)' % (mean_auc2))\n",
    "\n",
    "mean_tpr3a = mean_tpr3 / 10\n",
    "mean_auc3 = auc(mean_fpr, mean_tpr3a)\n",
    "plt.plot(mean_fpr,mean_tpr3a,lw=2,label='GRU1 Mean ROC (area = %0.2f)' % (mean_auc3))\n",
    "\n",
    "mean_tpr4a = mean_tpr4 / 10\n",
    "mean_auc4 = auc(mean_fpr, mean_tpr4a)\n",
    "plt.plot(mean_fpr,mean_tpr4a,lw=2,label='GRU2 Mean ROC (area = %0.2f)' % (mean_auc4))\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98f1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54269452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accurracy and Recall:\n",
      "LSTM 1: 99.10313904285431, 95.90163946151733\n",
      "LSTM 2: 99.10293817520142, 95.90163946151733\n",
      "GRU 1: 99.32735443115234, 95.73770523071289\n",
      "GRU 2: 99.26003932952881, 95.4071033000946\n"
     ]
    }
   ],
   "source": [
    "# Look at average accuracy and recall\n",
    "avg_acc1 = np.average(acc_per_fold1)\n",
    "avg_acc2 = np.average(acc_per_fold2)\n",
    "avg_acc3 = np.average(acc_per_fold3)\n",
    "avg_acc4 = np.average(acc_per_fold4)\n",
    "\n",
    "avg_recall1 = np.average(recall_per_fold1)\n",
    "avg_recall2 = np.average(recall_per_fold2)\n",
    "avg_recall3 = np.average(recall_per_fold3)\n",
    "avg_recall4 = np.average(recall_per_fold4)\n",
    "\n",
    "print(\"Average Accurracy and Recall:\")\n",
    "print(f\"LSTM 1: {avg_acc1}, {avg_recall1}\")\n",
    "print(f\"LSTM 2: {avg_acc2}, {avg_recall2}\")\n",
    "print(f\"GRU 1: {avg_acc3}, {avg_recall3}\")\n",
    "print(f\"GRU 2: {avg_acc4}, {avg_recall4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e641a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcnemar test\n",
    "def mcnemar(y_pred1, y_pred2, y_actual):\n",
    "    a,b,c = 0,0,0\n",
    "    for i in range(y_actual.size):\n",
    "        model1, model2 = False, False\n",
    "        if y_pred1[i] == y_actual[i]:\n",
    "            model1 = True\n",
    "        if y_pred2[i] == y_actual[i]:\n",
    "            model2 = True\n",
    "        \n",
    "        if model1 and model2:\n",
    "            a += 1\n",
    "        elif model1:\n",
    "            b += 1\n",
    "        elif model2:\n",
    "            c += 1\n",
    "    if(b-c == 0):\n",
    "        return False\n",
    "    \n",
    "    if ((abs(b-c)-1)**2)/(b+c) > 3.841:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f0e3ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "70/70 [==============================] - 18s 249ms/step - loss: 0.0067 - accuracy: 0.9973 - recall_36: 0.9868\n",
      "Epoch 2/3\n",
      "70/70 [==============================] - 24s 338ms/step - loss: 0.0063 - accuracy: 0.9982 - recall_36: 0.9901\n",
      "Epoch 3/3\n",
      "70/70 [==============================] - 23s 325ms/step - loss: 0.0045 - accuracy: 0.9982 - recall_36: 0.9885\n",
      "Epoch 1/3\n",
      "70/70 [==============================] - 21s 299ms/step - loss: 0.0078 - accuracy: 0.9980 - recall_37: 0.9918\n",
      "Epoch 2/3\n",
      "70/70 [==============================] - 27s 393ms/step - loss: 0.0058 - accuracy: 0.9984 - recall_37: 0.9918\n",
      "Epoch 3/3\n",
      "70/70 [==============================] - 22s 311ms/step - loss: 0.0051 - accuracy: 0.9989 - recall_37: 0.9934\n",
      "Epoch 1/3\n",
      "70/70 [==============================] - 19s 266ms/step - loss: 0.0045 - accuracy: 0.9987 - recall_38: 0.9967\n",
      "Epoch 2/3\n",
      "70/70 [==============================] - 20s 279ms/step - loss: 0.0032 - accuracy: 0.9991 - recall_38: 0.9967\n",
      "Epoch 3/3\n",
      "70/70 [==============================] - 19s 269ms/step - loss: 0.0051 - accuracy: 0.9980 - recall_38: 0.9934\n",
      "Epoch 1/3\n",
      "70/70 [==============================] - 19s 271ms/step - loss: 0.0058 - accuracy: 0.9984 - recall_39: 0.9918\n",
      "Epoch 2/3\n",
      "70/70 [==============================] - 19s 277ms/step - loss: 0.0043 - accuracy: 0.9989 - recall_39: 0.9951\n",
      "Epoch 3/3\n",
      "70/70 [==============================] - 18s 264ms/step - loss: 0.0038 - accuracy: 0.9991 - recall_39: 0.9951\n",
      "35/35 [==============================] - 2s 45ms/step\n",
      "35/35 [==============================] - 2s 47ms/step\n",
      "35/35 [==============================] - 1s 38ms/step\n",
      "35/35 [==============================] - 1s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm1.fit(X_train, y_train, epochs=3, batch_size=64, verbose=1)\n",
    "lstm2.fit(X_train, y_train, epochs=3, batch_size=64, verbose=1)\n",
    "gru1.fit(X_train, y_train, epochs=3, batch_size=64, verbose=1)\n",
    "gru2.fit(X_train, y_train, epochs=3, batch_size=64, verbose=1)\n",
    "\n",
    "yhat_prob1 = lstm1.predict(X_test)\n",
    "yhat_prob2 = lstm2.predict(X_test)\n",
    "yhat_prob3 = gru1.predict(X_test)\n",
    "yhat_prob4 = gru2.predict(X_test)\n",
    "\n",
    "yhat1 = np.round(yhat_prob1)\n",
    "yhat2 = np.round(yhat_prob2)\n",
    "yhat3 = np.round(yhat_prob3)\n",
    "yhat4 = np.round(yhat_prob4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b2a7e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar Tests\n",
      "LSTM1 vs. LSTM2: False\n",
      "GRU1 vs. GRU2: False\n",
      "LSTM1 vs. GRU1: False\n",
      "LSTM2 vs. GRU2: False\n",
      "LSTM1 vs. GRU2: False\n",
      "GRU1 vs. LSTM2: True\n"
     ]
    }
   ],
   "source": [
    "print(\"McNemar Tests\")\n",
    "print(f\"LSTM1 vs. LSTM2: {mcnemar(yhat1,yhat2,y_test)}\")\n",
    "print(f\"GRU1 vs. GRU2: {mcnemar(yhat3,yhat4,y_test)}\")\n",
    "print(f\"LSTM1 vs. GRU1: {mcnemar(yhat1,yhat3,y_test)}\")\n",
    "print(f\"LSTM2 vs. GRU2: {mcnemar(yhat2,yhat4,y_test)}\")\n",
    "print(f\"LSTM1 vs. GRU2: {mcnemar(yhat1,yhat4,y_test)}\")\n",
    "print(f\"GRU1 vs. LSTM2: {mcnemar(yhat3,yhat2,y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a184c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d69864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
