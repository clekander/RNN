{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52826d40",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Gabs DiLiegro, London Kasper, Carys LeKander\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset?select=spam.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565fb1a1",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Our dataset is a collection of text messages that are identified as normal or spam texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51360b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      5572 non-null   object\n",
      " 1   v2      5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('spam.csv',encoding='latin-1')\n",
    "df = df.drop(['Unnamed: 2','Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83598b",
   "metadata": {},
   "source": [
    "The first column of our dataset identifies if it is a spam text. We used label encoding below to change the column to be 0 for a normal text and 1 for a spam text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f7e0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['v1'])\n",
    "df['v1'] = le.transform(df['v1'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af1766",
   "metadata": {},
   "source": [
    "Looking at the totals for each category, we can see that there are many more normal text messages than spam messages in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5991375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals = df['v1'].value_counts()\n",
    "totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fbb2d2",
   "metadata": {},
   "source": [
    "The longest text message in our dataset is 171 which we will use for our max length during tokenization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e71155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 0\n",
    "for i in df.v2:\n",
    "    if len(i.split()) > max_words:\n",
    "        max_words = len(i.split())\n",
    "max_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6187c0",
   "metadata": {},
   "source": [
    "For our tokenization, we converted each word to an integer using the Keras Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06fa4d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 03:12:49.690524: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8920 unique tokens. Distilled to 8920 top words.\n",
      "Shape of data tensor: (5572, 171)\n",
      "CPU times: user 4.75 s, sys: 698 ms, total: 5.45 s\n",
      "Wall time: 6.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "NUM_TOP_WORDS = None # use entire vocabulary!\n",
    "MAX_ART_LEN = max_words # maximum and minimum number of words\n",
    "\n",
    "#tokenize the text\n",
    "tokenizer = Tokenizer(num_words=NUM_TOP_WORDS)\n",
    "tokenizer.fit_on_texts(df.v2)\n",
    "# save as sequences with integers replacing words\n",
    "sequences = tokenizer.texts_to_sequences(df.v2)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "NUM_TOP_WORDS = len(word_index) if NUM_TOP_WORDS==None else NUM_TOP_WORDS\n",
    "top_words = min((len(word_index),NUM_TOP_WORDS))\n",
    "print('Found %s unique tokens. Distilled to %d top words.' % (len(word_index),top_words))\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "y = df.v1.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61fa95",
   "metadata": {},
   "source": [
    "For our business case, we want to notify users when they recieve a text that may be spam. If we misclassify something as spam, the user may be slightly annoyed. However, if we do not clasify something as spam when it is, it could lead to the user trusting a fraudulent text. Therefore we want to minimize the number of false negative (number of spam texts classified as normal texts), so we will use recall to measure our algorithm's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58da1a",
   "metadata": {},
   "source": [
    "We chose to use a Stratified 10-fold cross validation for dividing our data into training and testing. We chose this method because our dataset is smaller (5572) and there are not many examples of spam texts (747). We want to make sure that we represent the entire dataset in equal proportion.\n",
    "\n",
    "MAYBE ADD MORE EXPLANATION TO THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b083d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "y_train = y_train.values.astype(np.int32)\n",
    "y_test = y_test.values.astype(np.int32)\n",
    "kfold = StratifiedKFold(n_splits=10).split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542cad62",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ca36fa",
   "metadata": {},
   "source": [
    "***Investigate at least two different recurrent network architectures (perhaps LSTM and GRU). Alternatively, you may also choose one recurrent network and one convolutional network. Be sure to use an embedding layer (try to use a pre-trained embedding, if possible). Adjust hyper-parameters of the networks as needed to improve generalization performance (train a total of at least four models). Discuss the performance of each network and compare them.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7bb7789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "Embedding Shape: (8921, 100) \n",
      " Total words found: 6518 \n",
      " Percentage: 73.06355789709674\n",
      "CPU times: user 10.1 s, sys: 305 ms, total: 10.4 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EMBED_SIZE = 100\n",
    "# the embed size should match the file you load glove from\n",
    "embeddings_index = {}\n",
    "f = open('large_data/glove.6b/glove.6B.100d.txt')\n",
    "# save key/array pairs of the embeddings\n",
    "#  the key of the dictionary is the word, the array is the embedding\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# now fill in the matrix, using the ordering from the\n",
    "#  keras word tokenizer from before\n",
    "found_words = 0\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be ALL-ZEROS\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        found_words = found_words+1\n",
    "\n",
    "print(\"Embedding Shape:\",embedding_matrix.shape, \"\\n\",\n",
    "      \"Total words found:\",found_words, \"\\n\",\n",
    "      \"Percentage:\",100*found_words/embedding_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbfd30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, GRU\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07ecd657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this embedding now\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBED_SIZE,\n",
    "                            weights=[embedding_matrix],# here is the embedding getting saved\n",
    "                            input_length=MAX_ART_LEN,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bd4b143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 171, 100)          892100    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 972,601\n",
      "Trainable params: 80,501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 03:13:07.073628: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 892,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm1 = Sequential()\n",
    "lstm1.add(embedding_layer)\n",
    "lstm1.add(LSTM(100,dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(lstm1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db12c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 171, 100)          892100    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 972,601\n",
      "Trainable params: 80,501\n",
      "Non-trainable params: 892,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm2 = Sequential()\n",
    "lstm2.add(embedding_layer)\n",
    "lstm2.add(LSTM(100,dropout=0.2, recurrent_dropout=0.3))\n",
    "lstm2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(lstm2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b9871c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 171, 100)          892100    \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 100)               60600     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 952,801\n",
      "Trainable params: 60,701\n",
      "Non-trainable params: 892,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gru1 = Sequential()\n",
    "gru1.add(embedding_layer)\n",
    "gru1.add(GRU(100,dropout=0.2, recurrent_dropout=0.2))\n",
    "gru1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(gru1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76950efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 171, 100)          892100    \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 100)               60600     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 952,801\n",
      "Trainable params: 60,701\n",
      "Non-trainable params: 892,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gru2 = Sequential()\n",
    "gru2.add(embedding_layer)\n",
    "gru2.add(GRU(100,dropout=0.2, recurrent_dropout=0.3))\n",
    "gru2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(gru2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0785bfc",
   "metadata": {},
   "source": [
    "**Use the method of train/test splitting and evaluation criteria that you argued for at the beginning of the lab. Visualize the results of all the RNNs you trained.  Use proper statistical comparison techniques to determine which method(s) is (are) superior.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8e05aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "def roc(model, test, train, mean_tpr):\n",
    "    probas = model.predict(X_train[test], verbose=0)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train[test], probas, pos_label=1)\n",
    "    mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "    return mean_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd3e7c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1 ...\n",
      "Score for LSTM1: loss of 0.09335790574550629; accuracy of 95.96412777900696%; recall of 93.44262480735779%\n",
      "Score for LSTM2: loss of 0.08601104468107224; accuracy of 97.98206090927124%; recall_1 of 86.8852436542511%\n",
      "Score for GRU1: loss of 0.06690991669893265; accuracy of 98.20627570152283%; recall_2 of 91.80327653884888%\n",
      "Score for GRU2: loss of 0.08441730588674545; accuracy of 97.98206090927124%; recall_3 of 86.8852436542511%\n",
      "Training for fold 2 ...\n",
      "Score for LSTM1: loss of 0.07476350665092468; accuracy of 97.98206090927124%; recall_4 of 86.8852436542511%\n",
      "Score for LSTM2: loss of 0.10344936698675156; accuracy of 96.41255736351013%; recall_5 of 75.40983557701111%\n",
      "Score for GRU1: loss of 0.10055604577064514; accuracy of 96.8609869480133%; recall_6 of 78.68852615356445%\n",
      "Score for GRU2: loss of 0.07904259115457535; accuracy of 97.53363132476807%; recall_7 of 83.60655903816223%\n",
      "Training for fold 3 ...\n",
      "Score for LSTM1: loss of 0.021923579275608063; accuracy of 99.55157041549683%; recall_8 of 96.72130942344666%\n",
      "Score for LSTM2: loss of 0.016027508303523064; accuracy of 99.55157041549683%; recall_9 of 96.72130942344666%\n",
      "Score for GRU1: loss of 0.014724038541316986; accuracy of 99.77578520774841%; recall_10 of 98.36065769195557%\n",
      "Score for GRU2: loss of 0.02082170732319355; accuracy of 99.32735562324524%; recall_11 of 96.72130942344666%\n",
      "Training for fold 4 ...\n",
      "Score for LSTM1: loss of 0.03825664147734642; accuracy of 99.10314083099365%; recall_12 of 93.44262480735779%\n",
      "Score for LSTM2: loss of 0.03369613364338875; accuracy of 99.10314083099365%; recall_13 of 95.08196711540222%\n",
      "Score for GRU1: loss of 0.04174990579485893; accuracy of 98.87892603874207%; recall_14 of 91.80327653884888%\n",
      "Score for GRU2: loss of 0.03562483191490173; accuracy of 98.87892603874207%; recall_15 of 91.80327653884888%\n",
      "Training for fold 5 ...\n",
      "Score for LSTM1: loss of 0.019123844802379608; accuracy of 99.77578520774841%; recall_16 of 98.36065769195557%\n",
      "Score for LSTM2: loss of 0.022097134962677956; accuracy of 99.32735562324524%; recall_17 of 95.08196711540222%\n",
      "Score for GRU1: loss of 0.012646188028156757; accuracy of 99.55157041549683%; recall_18 of 98.36065769195557%\n",
      "Score for GRU2: loss of 0.01581442542374134; accuracy of 99.77578520774841%; recall_19 of 98.36065769195557%\n",
      "Training for fold 6 ...\n",
      "Score for LSTM1: loss of 0.017438698559999466; accuracy of 99.55157041549683%; recall_20 of 96.72130942344666%\n",
      "Score for LSTM2: loss of 0.0161662045866251; accuracy of 99.32735562324524%; recall_21 of 96.72130942344666%\n",
      "Score for GRU1: loss of 0.012158489786088467; accuracy of 99.77578520774841%; recall_22 of 98.36065769195557%\n",
      "Score for GRU2: loss of 0.012635982595384121; accuracy of 99.55157041549683%; recall_23 of 96.72130942344666%\n",
      "Training for fold 7 ...\n",
      "Score for LSTM1: loss of 0.00958857499063015; accuracy of 99.77578520774841%; recall_24 of 98.36065769195557%\n",
      "Score for LSTM2: loss of 0.009994667023420334; accuracy of 99.55157041549683%; recall_25 of 96.72130942344666%\n",
      "Score for GRU1: loss of 0.0053047556430101395; accuracy of 99.55157041549683%; recall_26 of 96.72130942344666%\n",
      "Score for GRU2: loss of 0.00223149242810905; accuracy of 100.0%; recall_27 of 100.0%\n",
      "Training for fold 8 ...\n",
      "Score for LSTM1: loss of 0.0023731302935630083; accuracy of 100.0%; recall_28 of 100.0%\n",
      "Score for LSTM2: loss of 0.0024545015767216682; accuracy of 100.0%; recall_29 of 100.0%\n",
      "Score for GRU1: loss of 0.0009808336617425084; accuracy of 100.0%; recall_30 of 100.0%\n",
      "Score for GRU2: loss of 0.0035728327929973602; accuracy of 99.77527856826782%; recall_31 of 98.33333492279053%\n",
      "Training for fold 9 ...\n",
      "Score for LSTM1: loss of 0.0011556483805179596; accuracy of 100.0%; recall_32 of 100.0%\n",
      "Score for LSTM2: loss of 0.023951897397637367; accuracy of 99.32584166526794%; recall_33 of 100.0%\n",
      "Score for GRU1: loss of 0.0006440345896407962; accuracy of 100.0%; recall_34 of 100.0%\n",
      "Score for GRU2: loss of 0.0006191498250700533; accuracy of 100.0%; recall_35 of 100.0%\n",
      "Training for fold 10 ...\n",
      "Score for LSTM1: loss of 0.004056060686707497; accuracy of 100.0%; recall_36 of 100.0%\n",
      "Score for LSTM2: loss of 0.0024320094380527735; accuracy of 100.0%; recall_37 of 100.0%\n",
      "Score for GRU1: loss of 0.00048474469804205; accuracy of 100.0%; recall_38 of 100.0%\n",
      "Score for GRU2: loss of 0.00026012927992269397; accuracy of 100.0%; recall_39 of 100.0%\n",
      "CPU times: user 1h 41min 54s, sys: 17min 23s, total: 1h 59min 18s\n",
      "Wall time: 38min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc_per_fold1 = []\n",
    "recall_per_fold1 = []\n",
    "loss_per_fold1 = []\n",
    "mean_tpr1 = 0.0\n",
    "\n",
    "acc_per_fold2 = []\n",
    "recall_per_fold2 = []\n",
    "loss_per_fold2 = []\n",
    "mean_tpr2 = 0.0\n",
    "\n",
    "acc_per_fold3 = []\n",
    "recall_per_fold3 = []\n",
    "loss_per_fold3 = []\n",
    "mean_tpr3 = 0.0\n",
    "\n",
    "acc_per_fold4 = []\n",
    "recall_per_fold4 = []\n",
    "loss_per_fold4 = []\n",
    "mean_tpr4 = 0.0\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "\n",
    "    # Compile the model\n",
    "    lstm1.compile(loss='binary_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy', keras.metrics.Recall()])\n",
    "    lstm2.compile(loss='binary_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy', keras.metrics.Recall()])\n",
    "    gru1.compile(loss='binary_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy', keras.metrics.Recall()])\n",
    "    gru2.compile(loss='binary_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy', keras.metrics.Recall()])\n",
    "\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {k+1} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    history1 = lstm1.fit(X_train[train], y_train[train], epochs=3, batch_size=64, validation_data=(X_train[test], y_train[test],), verbose=0)\n",
    "    history2 = lstm2.fit(X_train[train], y_train[train], epochs=3, batch_size=64, validation_data=(X_train[test], y_train[test],), verbose=0)\n",
    "    history3 = gru1.fit(X_train[train], y_train[train], epochs=3, batch_size=64, validation_data=(X_train[test], y_train[test],), verbose=0)\n",
    "    history4 = gru2.fit(X_train[train], y_train[train], epochs=3, batch_size=64, validation_data=(X_train[test], y_train[test],), verbose=0)\n",
    "\n",
    "    mean_tpr1 = roc(lstm1, test, train, mean_tpr1)\n",
    "    mean_tpr2 = roc(lstm2, test, train, mean_tpr2)\n",
    "    mean_tpr3 = roc(gru1, test, train, mean_tpr3)\n",
    "    mean_tpr4 = roc(gru2, test, train, mean_tpr4)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores1 = lstm1.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "    scores2 = lstm2.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "    scores3 = gru1.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "    scores4 = gru2.evaluate(X_train[test], y_train[test], verbose=0)\n",
    "\n",
    "    print(f'Score for LSTM1: {lstm1.metrics_names[0]} of {scores1[0]}; {lstm1.metrics_names[1]} of {scores1[1]*100}%; {lstm1.metrics_names[2]} of {scores1[2]*100}%')\n",
    "    print(f'Score for LSTM2: {lstm2.metrics_names[0]} of {scores2[0]}; {lstm2.metrics_names[1]} of {scores2[1]*100}%; {lstm2.metrics_names[2]} of {scores2[2]*100}%')\n",
    "    print(f'Score for GRU1: {gru1.metrics_names[0]} of {scores3[0]}; {gru1.metrics_names[1]} of {scores3[1]*100}%; {gru1.metrics_names[2]} of {scores3[2]*100}%')\n",
    "    print(f'Score for GRU2: {gru2.metrics_names[0]} of {scores4[0]}; {gru2.metrics_names[1]} of {scores4[1]*100}%; {gru2.metrics_names[2]} of {scores4[2]*100}%')\n",
    "\n",
    "    loss_per_fold1.append(scores1[0])\n",
    "    acc_per_fold1.append(scores1[1] * 100)\n",
    "    recall_per_fold1.append(scores1[2]*100)\n",
    "    loss_per_fold2.append(scores2[0])\n",
    "    acc_per_fold2.append(scores2[1] * 100)\n",
    "    recall_per_fold2.append(scores2[2]*100)\n",
    "    loss_per_fold3.append(scores3[0])\n",
    "    acc_per_fold3.append(scores3[1] * 100)\n",
    "    recall_per_fold3.append(scores3[2]*100)\n",
    "    loss_per_fold4.append(scores4[0])\n",
    "    acc_per_fold4.append(scores4[1] * 100)\n",
    "    recall_per_fold4.append(scores4[2]*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556476b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
